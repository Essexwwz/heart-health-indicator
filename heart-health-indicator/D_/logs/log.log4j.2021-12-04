[ERROR] 2021-12-04 13:44:40,797(2) --> [dispatcher-event-loop-0] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in statusUpdate  
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@67a78aca rejected from java.util.concurrent.ThreadPoolExecutor@6d0fd314[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:769)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:745)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:71)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[ERROR] 2021-12-04 15:48:50,343(1) --> [Executor task launch worker for task 0.0 in stage 14.0 (TID 8)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 14.0 (TID 8)  
java.lang.NumberFormatException: For input string: "[1.0]"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:318)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:318)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at corr$.$anonfun$main$2(corr.scala:32)
	at corr$.$anonfun$main$2$adapted(corr.scala:32)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:957)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:950)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1884)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1878)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:482)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[ERROR] 2021-12-04 15:48:50,384(42) --> [task-result-getter-0] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 14.0 failed 1 times; aborting job  
[ERROR] 2021-12-04 15:49:59,668(0) --> [Executor task launch worker for task 0.0 in stage 14.0 (TID 8)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 14.0 (TID 8)  
java.lang.NumberFormatException: For input string: "[40.0]"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:318)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:318)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at corr$.$anonfun$main$6(corr.scala:44)
	at corr$.$anonfun$main$6$adapted(corr.scala:44)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:957)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:950)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1884)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1878)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:482)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[ERROR] 2021-12-04 15:49:59,700(32) --> [task-result-getter-0] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 14.0 failed 1 times; aborting job  
[ERROR] 2021-12-04 15:52:51,828(1) --> [Executor task launch worker for task 0.0 in stage 14.0 (TID 8)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 14.0 (TID 8)  
java.lang.NumberFormatException: For input string: "[1.0]"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:318)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:318)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at corr$.$anonfun$main$2(corr.scala:32)
	at corr$.$anonfun$main$2$adapted(corr.scala:32)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:957)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:950)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1884)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1878)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:482)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[ERROR] 2021-12-04 15:52:51,867(40) --> [task-result-getter-0] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 14.0 failed 1 times; aborting job  
[ERROR] 2021-12-04 15:53:58,962(1) --> [Executor task launch worker for task 0.0 in stage 14.0 (TID 8)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 14.0 (TID 8)  
java.lang.NumberFormatException: For input string: "[1.0]"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:318)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:318)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at corr$.$anonfun$main$2(corr.scala:32)
	at corr$.$anonfun$main$2$adapted(corr.scala:32)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:957)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:950)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1884)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1878)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:482)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[ERROR] 2021-12-04 15:53:58,996(35) --> [task-result-getter-0] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 14.0 failed 1 times; aborting job  
[ERROR] 2021-12-04 15:57:45,457(1) --> [Executor task launch worker for task 0.0 in stage 14.0 (TID 8)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 14.0 (TID 8)  
java.lang.NumberFormatException: For input string: "[1.0]"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:318)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:318)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at corr$.$anonfun$main$2(corr.scala:32)
	at corr$.$anonfun$main$2$adapted(corr.scala:32)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:957)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:950)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1884)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1878)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:482)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[ERROR] 2021-12-04 15:57:45,502(46) --> [task-result-getter-0] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 14.0 failed 1 times; aborting job  
[ERROR] 2021-12-04 15:59:37,108(1) --> [Executor task launch worker for task 0.0 in stage 26.0 (TID 14)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 26.0 (TID 14)  
java.lang.NumberFormatException: For input string: "[40.0]"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:318)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:318)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at corr$.$anonfun$main$7(corr.scala:44)
	at corr$.$anonfun$main$7$adapted(corr.scala:44)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:957)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:950)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1884)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1878)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:482)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[ERROR] 2021-12-04 15:59:37,143(36) --> [task-result-getter-2] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 26.0 failed 1 times; aborting job  
[ERROR] 2021-12-04 16:00:33,567(1) --> [Executor task launch worker for task 0.0 in stage 26.0 (TID 14)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 26.0 (TID 14)  
java.lang.NumberFormatException: For input string: "[40.0]"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:318)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:318)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at corr$.$anonfun$main$6(corr.scala:44)
	at corr$.$anonfun$main$6$adapted(corr.scala:44)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:957)
	at org.apache.spark.rdd.RDD$$anon$3.next(RDD.scala:950)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1884)
	at org.apache.spark.util.Utils$$anon$6.next(Utils.scala:1878)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:482)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[ERROR] 2021-12-04 16:00:33,602(36) --> [task-result-getter-2] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 26.0 failed 1 times; aborting job  
