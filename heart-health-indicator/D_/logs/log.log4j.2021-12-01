[ERROR] 2021-12-01 20:16:03,597(1) --> [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 1.0 (TID 1)  
java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at org.apache.spark.sql.Row.getDouble(Row.scala:270)
	at org.apache.spark.sql.Row.getDouble$(Row.scala:270)
	at org.apache.spark.sql.catalyst.expressions.GenericRow.getDouble(rows.scala:166)
	at csvreader$.$anonfun$main$2(csvreader.scala:19)
	at csvreader$.$anonfun$main$2$adapted(csvreader.scala:18)
	at scala.collection.immutable.Range.foreach(Range.scala:156)
	at csvreader$.$anonfun$main$1(csvreader.scala:18)
	at org.apache.spark.sql.execution.MapElementsExec.$anonfun$doExecute$11(objects.scala:300)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at scala.collection.Iterator.foreach(Iterator.scala:944)
	at scala.collection.Iterator.foreach$(Iterator.scala:944)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:59)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:50)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:310)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:308)
	at scala.collection.AbstractIterator.to(Iterator.scala:1432)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:302)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:302)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1432)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:289)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:283)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1432)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[ERROR] 2021-12-01 20:16:03,659(63) --> [task-result-getter-1] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 1.0 failed 1 times; aborting job  
[ERROR] 2021-12-01 22:10:32,064(0) --> [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 4.0 (TID 4)  
java.lang.NoClassDefFoundError: scala/Product$class
	at breeze.math.Complex.<init>(Complex.scala:34)
	at breeze.math.Complex$scalar$.<init>(Complex.scala:221)
	at breeze.math.Complex$scalar$.<clinit>(Complex.scala)
	at breeze.math.Ring$.<init>(Ring.scala:43)
	at breeze.math.Ring$.<clinit>(Ring.scala)
	at breeze.linalg.DenseVector$.<init>(DenseVector.scala:774)
	at breeze.linalg.DenseVector$.<clinit>(DenseVector.scala)
	at breeze.linalg.DenseVector.<init>(DenseVector.scala:65)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:53)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:60)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:126)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:123)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157)
	at scala.collection.Iterator.foreach(Iterator.scala:944)
	at scala.collection.Iterator.foreach$(Iterator.scala:944)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1432)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:214)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1432)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: scala.Product$class
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 38 more
[ERROR] 2021-12-01 22:10:32,107(43) --> [task-result-getter-0] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 4.0 failed 1 times; aborting job  
[ERROR] 2021-12-01 22:11:50,174(1) --> [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 4.0 (TID 4)  
java.lang.NoClassDefFoundError: scala/Product$class
	at breeze.math.Complex.<init>(Complex.scala:34)
	at breeze.math.Complex$scalar$.<init>(Complex.scala:221)
	at breeze.math.Complex$scalar$.<clinit>(Complex.scala)
	at breeze.math.Ring$.<init>(Ring.scala:43)
	at breeze.math.Ring$.<clinit>(Ring.scala)
	at breeze.linalg.DenseVector$.<init>(DenseVector.scala:774)
	at breeze.linalg.DenseVector$.<clinit>(DenseVector.scala)
	at breeze.linalg.DenseVector.<init>(DenseVector.scala:65)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:53)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:60)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:126)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:123)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157)
	at scala.collection.Iterator.foreach(Iterator.scala:944)
	at scala.collection.Iterator.foreach$(Iterator.scala:944)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1432)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:214)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1432)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: scala.Product$class
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 38 more
[ERROR] 2021-12-01 22:11:50,224(51) --> [task-result-getter-0] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 4.0 failed 1 times; aborting job  
[ERROR] 2021-12-01 22:12:06,411(1) --> [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 4.0 (TID 4)  
java.lang.NoClassDefFoundError: scala/Product$class
	at breeze.math.Complex.<init>(Complex.scala:34)
	at breeze.math.Complex$scalar$.<init>(Complex.scala:221)
	at breeze.math.Complex$scalar$.<clinit>(Complex.scala)
	at breeze.math.Ring$.<init>(Ring.scala:43)
	at breeze.math.Ring$.<clinit>(Ring.scala)
	at breeze.linalg.DenseVector$.<init>(DenseVector.scala:774)
	at breeze.linalg.DenseVector$.<clinit>(DenseVector.scala)
	at breeze.linalg.DenseVector.<init>(DenseVector.scala:65)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:53)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:60)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:126)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:123)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157)
	at scala.collection.Iterator.foreach(Iterator.scala:944)
	at scala.collection.Iterator.foreach$(Iterator.scala:944)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1432)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:214)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1432)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: scala.Product$class
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 38 more
[ERROR] 2021-12-01 22:12:06,457(47) --> [task-result-getter-0] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 4.0 failed 1 times; aborting job  
[ERROR] 2021-12-01 22:13:33,515(1) --> [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 4.0 (TID 4)  
java.lang.NoClassDefFoundError: scala/Product$class
	at breeze.math.Complex.<init>(Complex.scala:34)
	at breeze.math.Complex$scalar$.<init>(Complex.scala:221)
	at breeze.math.Complex$scalar$.<clinit>(Complex.scala)
	at breeze.math.Ring$.<init>(Ring.scala:43)
	at breeze.math.Ring$.<clinit>(Ring.scala)
	at breeze.linalg.DenseVector$.<init>(DenseVector.scala:774)
	at breeze.linalg.DenseVector$.<clinit>(DenseVector.scala)
	at breeze.linalg.DenseVector.<init>(DenseVector.scala:65)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:53)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:60)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:126)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:123)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157)
	at scala.collection.Iterator.foreach(Iterator.scala:944)
	at scala.collection.Iterator.foreach$(Iterator.scala:944)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1432)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:214)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1432)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: scala.Product$class
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 38 more
[ERROR] 2021-12-01 22:13:33,572(58) --> [task-result-getter-0] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 4.0 failed 1 times; aborting job  
[ERROR] 2021-12-01 22:16:05,135(0) --> [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 5.0 (TID 5)  
java.lang.NoClassDefFoundError: scala/Product$class
	at breeze.math.Complex.<init>(Complex.scala:34)
	at breeze.math.Complex$scalar$.<init>(Complex.scala:221)
	at breeze.math.Complex$scalar$.<clinit>(Complex.scala)
	at breeze.math.Ring$.<init>(Ring.scala:43)
	at breeze.math.Ring$.<clinit>(Ring.scala)
	at breeze.linalg.DenseVector$.<init>(DenseVector.scala:774)
	at breeze.linalg.DenseVector$.<clinit>(DenseVector.scala)
	at breeze.linalg.DenseVector.<init>(DenseVector.scala:65)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:53)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:60)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:126)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:123)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157)
	at scala.collection.Iterator.foreach(Iterator.scala:944)
	at scala.collection.Iterator.foreach$(Iterator.scala:944)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1432)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:214)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1432)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: scala.Product$class
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 38 more
[ERROR] 2021-12-01 22:16:05,181(46) --> [task-result-getter-1] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 5.0 failed 1 times; aborting job  
[ERROR] 2021-12-01 22:16:30,544(0) --> [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 5.0 (TID 5)  
java.lang.NoClassDefFoundError: scala/Product$class
	at breeze.math.Complex.<init>(Complex.scala:34)
	at breeze.math.Complex$scalar$.<init>(Complex.scala:221)
	at breeze.math.Complex$scalar$.<clinit>(Complex.scala)
	at breeze.math.Ring$.<init>(Ring.scala:43)
	at breeze.math.Ring$.<clinit>(Ring.scala)
	at breeze.linalg.DenseVector$.<init>(DenseVector.scala:774)
	at breeze.linalg.DenseVector$.<clinit>(DenseVector.scala)
	at breeze.linalg.DenseVector.<init>(DenseVector.scala:65)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:53)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:60)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:126)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:123)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157)
	at scala.collection.Iterator.foreach(Iterator.scala:944)
	at scala.collection.Iterator.foreach$(Iterator.scala:944)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1432)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:214)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1432)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: scala.Product$class
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 38 more
[ERROR] 2021-12-01 22:16:30,590(46) --> [task-result-getter-1] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 5.0 failed 1 times; aborting job  
[ERROR] 2021-12-01 22:17:47,835(1) --> [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 5.0 (TID 5)  
java.lang.NoClassDefFoundError: scala/Product$class
	at breeze.math.Complex.<init>(Complex.scala:34)
	at breeze.math.Complex$scalar$.<init>(Complex.scala:221)
	at breeze.math.Complex$scalar$.<clinit>(Complex.scala)
	at breeze.math.Ring$.<init>(Ring.scala:43)
	at breeze.math.Ring$.<clinit>(Ring.scala)
	at breeze.linalg.DenseVector$.<init>(DenseVector.scala:774)
	at breeze.linalg.DenseVector$.<clinit>(DenseVector.scala)
	at breeze.linalg.DenseVector.<init>(DenseVector.scala:65)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:53)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:60)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:126)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:123)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157)
	at scala.collection.Iterator.foreach(Iterator.scala:944)
	at scala.collection.Iterator.foreach$(Iterator.scala:944)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1432)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:214)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1432)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: scala.Product$class
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 38 more
[ERROR] 2021-12-01 22:17:47,879(45) --> [task-result-getter-1] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 5.0 failed 1 times; aborting job  
[ERROR] 2021-12-01 22:19:53,383(0) --> [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 5.0 (TID 5)  
java.lang.NoClassDefFoundError: scala/Product$class
	at breeze.math.Complex.<init>(Complex.scala:34)
	at breeze.math.Complex$scalar$.<init>(Complex.scala:221)
	at breeze.math.Complex$scalar$.<clinit>(Complex.scala)
	at breeze.math.Ring$.<init>(Ring.scala:43)
	at breeze.math.Ring$.<clinit>(Ring.scala)
	at breeze.linalg.DenseVector$.<init>(DenseVector.scala:774)
	at breeze.linalg.DenseVector$.<clinit>(DenseVector.scala)
	at breeze.linalg.DenseVector.<init>(DenseVector.scala:65)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:53)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:60)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:126)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:123)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157)
	at scala.collection.Iterator.foreach(Iterator.scala:944)
	at scala.collection.Iterator.foreach$(Iterator.scala:944)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1432)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:214)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1432)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: scala.Product$class
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 38 more
[ERROR] 2021-12-01 22:19:53,432(49) --> [task-result-getter-1] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 5.0 failed 1 times; aborting job  
[ERROR] 2021-12-01 22:28:29,008(0) --> [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 2.0 (TID 2)  
scala.MatchError: [1] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)
	at org.apache.spark.ml.stat.Correlation$$anonfun$1.apply(Correlation.scala:70)
	at org.apache.spark.ml.stat.Correlation$$anonfun$1.apply(Correlation.scala:70)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at scala.collection.Iterator$SliceIterator.next(Iterator.scala:268)
	at scala.collection.Iterator.foreach(Iterator.scala:944)
	at scala.collection.Iterator.foreach$(Iterator.scala:944)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:59)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:50)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:310)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:308)
	at scala.collection.AbstractIterator.to(Iterator.scala:1432)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:302)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:302)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1432)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:289)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:283)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1432)
	at org.apache.spark.rdd.RDD.$anonfun$take$2(RDD.scala:1449)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[ERROR] 2021-12-01 22:28:29,053(45) --> [task-result-getter-2] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 2.0 failed 1 times; aborting job  
[ERROR] 2021-12-01 22:29:33,765(1) --> [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 2.0 (TID 2)  
scala.MatchError: [1] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)
	at org.apache.spark.ml.stat.Correlation$$anonfun$1.apply(Correlation.scala:70)
	at org.apache.spark.ml.stat.Correlation$$anonfun$1.apply(Correlation.scala:70)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:457)
	at scala.collection.Iterator$SliceIterator.next(Iterator.scala:268)
	at scala.collection.Iterator.foreach(Iterator.scala:944)
	at scala.collection.Iterator.foreach$(Iterator.scala:944)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:59)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:50)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:310)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:308)
	at scala.collection.AbstractIterator.to(Iterator.scala:1432)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:302)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:302)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1432)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:289)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:283)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1432)
	at org.apache.spark.rdd.RDD.$anonfun$take$2(RDD.scala:1449)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[ERROR] 2021-12-01 22:29:33,809(45) --> [task-result-getter-2] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 2.0 failed 1 times; aborting job  
[ERROR] 2021-12-01 22:32:49,978(1) --> [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 4.0 (TID 4)  
java.lang.NoClassDefFoundError: scala/Product$class
	at breeze.math.Complex.<init>(Complex.scala:34)
	at breeze.math.Complex$scalar$.<init>(Complex.scala:221)
	at breeze.math.Complex$scalar$.<clinit>(Complex.scala)
	at breeze.math.Ring$.<init>(Ring.scala:43)
	at breeze.math.Ring$.<clinit>(Ring.scala)
	at breeze.linalg.DenseVector$.<init>(DenseVector.scala:774)
	at breeze.linalg.DenseVector$.<clinit>(DenseVector.scala)
	at breeze.linalg.DenseVector.<init>(DenseVector.scala:65)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:53)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:60)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:126)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:123)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157)
	at scala.collection.Iterator.foreach(Iterator.scala:944)
	at scala.collection.Iterator.foreach$(Iterator.scala:944)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1432)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:214)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1432)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: scala.Product$class
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 38 more
[ERROR] 2021-12-01 22:32:50,022(45) --> [task-result-getter-0] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 4.0 failed 1 times; aborting job  
[ERROR] 2021-12-01 23:05:22,600(0) --> [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] org.apache.spark.internal.Logging.logError(Logging.scala:94): Exception in task 0.0 in stage 4.0 (TID 4)  
java.lang.NoClassDefFoundError: scala/Product$class
	at breeze.math.Complex.<init>(Complex.scala:34)
	at breeze.math.Complex$scalar$.<init>(Complex.scala:221)
	at breeze.math.Complex$scalar$.<clinit>(Complex.scala)
	at breeze.math.Ring$.<init>(Ring.scala:43)
	at breeze.math.Ring$.<clinit>(Ring.scala)
	at breeze.linalg.DenseVector$.<init>(DenseVector.scala:774)
	at breeze.linalg.DenseVector$.<clinit>(DenseVector.scala)
	at breeze.linalg.DenseVector.<init>(DenseVector.scala:65)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:53)
	at breeze.linalg.DenseVector$mcD$sp.<init>(DenseVector.scala:60)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:126)
	at org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$8.apply(RowMatrix.scala:123)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157)
	at scala.collection.Iterator.foreach(Iterator.scala:944)
	at scala.collection.Iterator.foreach$(Iterator.scala:944)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1432)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:214)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1432)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: scala.Product$class
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 38 more
[ERROR] 2021-12-01 23:05:22,651(51) --> [task-result-getter-0] org.apache.spark.internal.Logging.logError(Logging.scala:73): Task 0 in stage 4.0 failed 1 times; aborting job  
